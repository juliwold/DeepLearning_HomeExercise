{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_annotated = \"..\\\\data\\\\annotated_data\\\\train\"\n",
    "annotations = (\"my_annotations\", \"all_annotations\")\n",
    "\n",
    "# define split for training and validation\n",
    "split_train= 0.7 # s\n",
    "split_val=1-split_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Processing my_annotations.\n",
      "48 labels with image tiles.\n",
      "34 tiles drawn for training.\n",
      "--------\n",
      "Processing all_annotations.\n",
      "387 labels with image tiles.\n",
      "271 tiles drawn for training.\n"
     ]
    }
   ],
   "source": [
    "for a in annotations:\n",
    "    print(\"--------\")\n",
    "    print(f\"Processing {a}.\")\n",
    "    path_to_tiles = f\"{path_to_annotated}\\\\{a}\\\\annotated_tiles\"\n",
    "    output_dir = f\"{path_to_annotated}\\\\{a}\"\n",
    "    for i in (\"train\", \"val\"):\n",
    "        for j in (\"images\", \"labels\"):\n",
    "            os.makedirs(f\"{output_dir}\\\\{i}\\\\{j}\", exist_ok=True)\n",
    "\n",
    "    # Get a list of all the .txt files in the data directory\n",
    "    txt_files = [f for f in os.listdir(path_to_tiles) if f.endswith(\".txt\")]\n",
    "    img_files = [f for f in os.listdir(path_to_tiles) if f.endswith(\".tif\")]\n",
    "    txt_intersect = [f for f in txt_files if f.strip(\".txt\") in map(lambda x: x.strip(\".tif\"), img_files)]\n",
    "    print(f\"{len(txt_intersect)} labels with image tiles.\")\n",
    "\n",
    "    train_size = round(0.7 * len(txt_intersect))\n",
    "    print(f\"{train_size} tiles drawn for training.\")\n",
    "\n",
    "    random.seed(3254)\n",
    "    training_data = random.sample(txt_intersect, k = train_size)\n",
    "    test_data = [f in training_data for f in txt_intersect]\n",
    "\n",
    "    for i, label in enumerate(txt_intersect):\n",
    "        if test_data[i]:\n",
    "            dest_dir = f\"{output_dir}\\\\train\"\n",
    "        else:\n",
    "            dest_dir = f\"{output_dir}\\\\val\"\n",
    "        # Move label\n",
    "        src_label = os.path.join(path_to_tiles, label)\n",
    "        shutil.copy(src_label, f\"{dest_dir}\\\\labels\\\\{label}\")\n",
    "        # Move image\n",
    "        image = label.replace(\"txt\", \"tif\")\n",
    "        src_image = os.path.join(path_to_tiles, image)\n",
    "        shutil.copy(src_image, f\"{dest_dir}\\\\images\\\\{image}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
